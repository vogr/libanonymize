{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF442-PI9 | GDPR in practice: data anonymization\n",
    "\n",
    "### ~ Amine Chaabouni et Valentin Ogier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Ce projet présente l'application de méthodes d'analyse de données à un problème d'anonymisation : l'objectif est de censurer les noms de personnes dans un texte donné par l'utilisateur, et ce de manière tout à fait automatique. Ce problème est celui de la classification : on doit pouvoir distinguer entre la classe \"nom de personne\" et la classe formée par tous les autres mots de la langue du texte. Plus précisemment, on s'intéresse ici au problème de la _reconnaissance d'entités nommées_ (NER, de l'anglais *Named-entity recognition*) : dans un texte non structuré, on va faire ressortir des \"entités\" (i.e. un groupe de mots) en les catégorisant dans des classes (\"personne\" ou \"non-personne\" d'abord, puis \"personne\", \"lieu\", \"organisation\", etc ensuite).\n",
    "\n",
    "On dispose pour cela de plusieurs jeux de données :\n",
    "\n",
    "- `eng.train.conll` : un ensemble de phrases en anglais annoté, les annotations identifient certains groupes de mots comme des personnes, des lieux, ou autres. Ce jeu de donnée servira à l'entraînement de nos méthodes.\n",
    "- `eng.testa.conll` et `eng.testb.conll` : deux jeux de données de _test_ sur lesquels nous pourront évaler la performance de nos méthodes.\n",
    "\n",
    "L'objectif de ce projet est donc d'implémenter des méthodes d'analyse de données qui seront entraînées sur le premier jeu de données afin de repérer les noms de personnes dans les jeux de données de *test*. Chaque mot du texte étant vu comme une observation, nos méthodes seront des classifieurs : elles attribueront à chaque observation un label, et ces labels ne peuvent prendre qu'un nombre fini de valeur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Description du problème\n",
    "\n",
    "### 2.1 Reformulation\n",
    "\n",
    "Ce problème de reconnaissance d'entités nommées peut se décomposer en deux étapes :\n",
    "\n",
    "1. Transformation du texte en un ensemble de vecteurs, chaque vecteur correspondant à un mot du texte.\n",
    "2. Entraînement d'un classifieur sur cet ensemble de vecteur.\n",
    "\n",
    "Le succès de l'étape 2. dépend de la qualité de l'étape 1. : il faut non seulement que le représentant vectoriel d'un mot capture suffisament bien son sens, et son contexte, mais que la position relative de ces représentants dans l'espace vectoriel les englobants permettent de le comparer entre eux.\n",
    "\n",
    "Le modèle de langage [BERT](https://github.com/google-research/bert) constitue aujourd'hui une des méthodes les plus performantes pour effectuer la transformation 1. Les jeux de données décrits précédemment ont été transformés par BERT, et stockés sous forme de fichier binaire pouvant être chargé depuis Python et C++. Nous présenterons également dans ce rapport des transformations plus simples que nous avons implémentées nous-même.\n",
    "\n",
    "Pour réaliser l'étape 2, nous avons implémenté des classifieurs classiques de science des données, en prenant en compte les contraintes du problème.\n",
    "\n",
    "Nous analyserons dans ce rapport les méthodes que nous avons implémentés : les classifiers *k-nearest-neighbors* binaire et multiclasse, le classifieur binaire par régression logistique, et le classifieur multiclasse par régression logistique multinomiale. Nous les comparerons ces méthodes, et nous détaillerons les choix d'implémentation que nous avons effectués\n",
    "\n",
    "### 2.2 Les contraintes du problème\n",
    "\n",
    "Deux contraintes principales apparaissent lors de l'étude du problème :\n",
    "\n",
    "1. Les jeux de données ont des tailles considérable. Ils sont encore suffisament petit pour tenir intégralement en mémoire RAM : charger la version du jeu de données `eng.train.conll` transformée par BERT (à partir du fichier binaire `train.hdf5`) rempli à lui seul environ 1 GiB de mémoire RAM.\n",
    "2. Le ratio du nombre d'observations catégorisées \"I-PER\" sur le nombre total d'observations est faible dans le jeu de données d'entraînement ($\\approx$ 5%). Le nombre d'observations est encore plus faible pour \"I-LOC\", \"I-MISC\" et \"I-ORG\".\n",
    "\n",
    "Enfin, une remarque pratique sera importante pour l'évaluation des performances de nos classifieurs : la mesure pertinente est le taux de détéction $TD$ :\n",
    "\n",
    "\\begin{equation}\n",
    "TD = \\frac{N(\\text{positifs correctement identifiés})}{N(\\text{positifs dans jeu de données})}\n",
    "\\end{equation}\n",
    "\n",
    "En effet, dans un scénario d'anonymisation, le but est de retirer toutes les mentions de noms de personnes, quitte à avoir des faux positifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aspects techniques\n",
    "\n",
    "### 3.1 Fichier `README.md`\n",
    "\n",
    "Le fichier `README.md` dans le dossier principal de ce projet détaille comment préparer votre système pour y compilier notre projet. Il décrit également l'organisation des dossiers de ce projet, et explique également comment lancer les exemples C++, et le exemples Python.\n",
    "\n",
    "### 3.2. Architecture hybride Python / C++\n",
    "\n",
    "Notre projet présente une architecture hybride :\n",
    "\n",
    "- un _back-end_, partie du programme qui fait le gros des calculs et de la gestion de la mémoire, implémentée dans une librairie C++ appelée `libinfo9`.\n",
    "- un _front-end_ Python qui présente certaines fonctions et certains objets de la librairie `libinfo9` sous la forme de fonctions et d'objets Python dans une librairie Python appelée `info9`.\n",
    "\n",
    "Cette architecture permet d'utiliser les fonctions que nous avons implémentées en C++ dans un _Jupyter Notebook_, par exemple. Le _back-end_ C++ peut également être appelé depuis des programmes C++ traditionnels.\n",
    "\n",
    "L'architecture Python / C++ de notre projet est rendue possible par l'utilisation de la librairie [`pybind11`](https://pybind11.readthedocs.io/en/stable/intro.html) : celle-ci permet de créer des _bindings_ Python pour une librairie C++ existante. Les _bindings_ ainsi générés prennent la forme d'une librairie qui peut être importée par un script Python de manière transparente (i.e. le script Python n'a aucune connaissance de la librarie `pybind11` ; il contient simplement la ligne `import info9`).\n",
    "\n",
    "La librairie C++ `libinfo9` (en dehors d'un fichier `wrap.cpp` qui permet de générer les bindings) n'a elle-même aucune connaissance de la librairie `pybind11` : elle peut être compilée et utilisée par un programme C++ standard.\n",
    "\n",
    "La grande force de `pybind11` est donc de découpler très largement la partie C++ de la partie Python, tout en permettant des appels de fonction C++ par Python de façon peu coûteuse. Notre projet utilise notamment un mécanisme très intéressant de `pybind11` qui consiste à unifier deux types :\n",
    "\n",
    "- les `numpy.ndarray` de dimension 2 de la librairie `numpy` du côté Python\n",
    "- les `Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor>` de la librairie `Eigen` du côté C++, qui correspondent à une version \"row-major\" des `Eigen::MatrixXd`, qui sont elles stockées en \"column-major\". Par souci de simplicité, ce type a été renommé `RMatrixXd` dans notre code.\n",
    "\n",
    "En pratique, il est possible de faire transiter ces types entre la librairie C++ et le script Python **sans copie** ! De même, les `numpy.ndarray` de dimension 1 et les `Eigen::VectorXd` sont unifiés. `pybind11` permet également de gérer facilement la durée de vie des objets partagés (ou déplacés) entre C++ et Python en faisant coopérer les `std::shared_ptr` avec le _refcounting_ de Python.\n",
    "\n",
    "\n",
    "> **Exemple :** La fonction suivante définie dans le code C++ :\n",
    ">\n",
    ">```cpp\n",
    ">RMatrixXd add(Eigen::Ref<RMatrixXd const> const &a, Eigen::Ref<RMatrixXd const> const &b) {\n",
    ">     return a + b;\n",
    ">}\n",
    ">```\n",
    ">pourra être appelée par un script Python sans copie de ses arguments :\n",
    ">\n",
    ">```python\n",
    ">import info9\n",
    ">import numpy as np\n",
    ">A = np.array([1.,2.,3.])\n",
    ">B = info9.add(a, a) # zero-copy!\n",
    ">```\n",
    "\n",
    "### 3.3. Stockage des données\n",
    "    \n",
    "Les jeux de données ont été convertis au format [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format). Ce format de fichier binaire est très bien supporté depuis Python par la librairie [h5py](https://www.h5py.org/) qui permet d'y lire des données sous la forme de `numpy.ndarray`, et en C++ par la librairie [HighFive](https://github.com/BlueBrain/HighFive), qui permet d'y lire des données sous la forme d'objets `Eigen`.\n",
    "    \n",
    "    \n",
    "### 3.4. Librairies externes\n",
    "    \n",
    "Notre implémentation utilise quelques librairies externes :\n",
    "+ C++:\n",
    "    - [`pybind11`](https://pybind11.readthedocs.io/en/stable/intro.html) : pour générer une librairie Python à partir de la librairie C++.\n",
    "    - [`Eigen`](http://eigen.tuxfamily.org/) : calcul vectoriel et matriciel.\n",
    "    - [`ANN`](http://www.cs.umd.edu/~mount/ANN/) : implémentation de kd-trees pour le problème de la recherche des $k$ plus proches voisins.\n",
    "    - [`OpenMP`](https://www.openmp.org/) : le simple fait de *linker* `OpenMP` dans notre librairie active la parallélisation de certaines opérations matricielles de la librairie `Eigen`. \n",
    "    - [`HighFive`](https://github.com/BlueBrain/HighFive) : lecture/écriture de fichiers au format HDF5.\n",
    "+ Python:\n",
    "    - [`numpy`](https://numpy.org/) : calcul vectoriel et matriciel.\n",
    "    - [`pandas`](https://pandas.pydata.org/) : statistique sur des tableaux de données, ici simplement utilisée pour manipuler des fichiers csv.\n",
    "    - [`h5py`](https://www.h5py.org/) : lecture/écriture de fichiers au format HDF5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Problème de la classification binaire\n",
    "\n",
    "Commençons par nous intéresser au problème de la classification binaire (problème 5.1 de l'énoncé). On considére seulement deux classes dans notre jeu de de données : \"I-PER\" d'une part (marqué par 1), et tous le reste d'autre part (marqué par 0). On va ici travailler sur les jeux de données (textes annotés) préalablement transformés par BERT en des ensembles de vecteurs dans un espace de dimension 1024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Préparation\n",
    "\n",
    "Cette partie du notebook charge tous les paquets nécessaires à son exécution, pour cette partie et pour les suivantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger la librairie créée pour ce projet.\n",
    "# Avant d'exécuter cette ligne, suivre les instructions du README.md\n",
    "# pour l'installer dans votre environnement.\n",
    "import info9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les librairies externes, et des fonctionnalités de la\n",
    "# librairie standard Python\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables utiles dans la suite du rapport\n",
    "\n",
    "# Ensemble des labels IOB\n",
    "IOB_LABELS = [\"O\", \"B-MISC\", \"I-MISC\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\"]\n",
    "\n",
    "# Emplacement des jeux de données transformés par BERT\n",
    "# Un fichier HDF5 peut contenir plusieurs jeu de donnés (appelés `datasets`).\n",
    "# Ces fichiers contiennent deux datasets:\n",
    "#     - \"representation\" : représentations vectorielles des mots du texte.\n",
    "#     - \"true_labels\" : entiers correspondant aux labels IOB des mots du texte.\n",
    "ftrain_bert = Path(\"../data/train.hdf5\")\n",
    "ftesta_bert = Path(\"../data/testa.hdf5\")\n",
    "ftestb_bert = Path(\"../data/testa.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les vecteurs représentants les mots, et leurs labels seront stockés dans un objet `Dataset`, qui sera créé à partir d'un fichier HDF5 par la fonction suivante: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(fdataset, *, row_limit=None, projecter=None, label_of_interest=None,):\n",
    "    # Build Dataset containing row_limit rows of vectors, and the same number of labels.\n",
    "    # Optionnaly project the datapoints with `projecter` before building the Dataset.\n",
    "    # If label_of_interest is defined, the labels will be saved as binary in the Dataset:\n",
    "    #    -  1 if label == label_of_interest\n",
    "    #    -  0 in other cases\n",
    "    hf = h5py.File(fdataset, \"r\")\n",
    "    datapoints = hf[\"representation\"]\n",
    "    labels = hf[\"true_labels\"]\n",
    "    if row_limit:\n",
    "        datapoints = datapoints[:row_limit]\n",
    "        labels = labels[:row_limit]\n",
    "    if projecter:\n",
    "        datapoints = projecter.project(datapoints)\n",
    "    if label_of_interest:\n",
    "        labels = np.array(np.asarray(labels, dtype=int) == label_of_interest, dtype=int)\n",
    "    return info9.Dataset(datapoints, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Classifieur K-nn binaire\n",
    "\n",
    "Le classifieur K-nn binaire est défini dans le fichier `KnnClassificationBinary.hpp`. Son implémentation est très proche de celle qui a été proposée lors du TD6 du cours INF442. Nous allons le tester avec les paramètres suivants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of neighbors to consider\n",
    "k_nn = 10\n",
    "# Ratio of positive neighbors needed to predict that the point has a positive label\n",
    "positive_threshold = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarquons que nous n'avons pas pris le seuil de décision (`positive_threshold`) égal à 0.5 : le nombre de points négatifs étant très supérieur au nombre de points positifs, on peut considérer que les points positifs sont plus significatifs que les points négatifs. Cette idée sera développée dans la partie _Classifieur K-nn multilabel_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sans projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = read_dataset(ftrain_bert, row_limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 201 ms, sys: 20.6 ms, total: 222 ms\n",
      "Wall time: 221 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = info9.KnnClassificationBinary(k_nn, training_dataset, positive_threshold)\n",
    "training_dataset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La phase d'entraînement (qui se réduit à la construction d'un kd-tree) est très rapide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = read_dataset(ftesta_bert, row_limit=130, label_of_interest=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.46 s, sys: 4.83 ms, total: 1.46 s\n",
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "confusion_matrix = classifier.estimate_all(test_dataset)\n",
    "#print(confusion_matrix.PrintEvaluation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans projection, la classification est lente même avec un \"petit\" nombre de voisins à considérer (ici 20000) : l'estimation sur 100 vecteurs du jeu de données test prend presque deux secondes sur mon PC. On a choisi de na pas afficher la matric de confusion de ces estimations : le nombre d'estimation étant très faible, les résultats obtenus sont peu pertinents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec projection\n",
    "\n",
    "Pour diminuer le coût des estimations, on va se placer dans un espace de plus petite dimension en projetant les vecteurs de dimension 1024 représentant les mots dans un espace de dimension 128. L'objet utilisé est défini dans la classe `RandomProjection.hpp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_projecter = info9.RandomProjection(1024, 128, \"Rademacher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = read_dataset(ftrain_bert, row_limit=10000, projecter=random_projecter, label_of_interest=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.2 ms, sys: 8.24 ms, total: 55.5 ms\n",
      "Wall time: 51.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = info9.KnnClassificationBinary(k_nn, training_dataset, positive_threshold)\n",
    "training_dataset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les 130 premières lignes, pour comparer avec le cas sans projection :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = read_dataset(ftesta_bert, row_limit=130,projecter=random_projecter, label_of_interest=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 505 ms, sys: 452 µs, total: 505 ms\n",
      "Wall time: 476 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "confusion_matrix = classifier.estimate_all(test_dataset)\n",
    "#print(confusion_matrix.PrintEvaluation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur un exemple plus significatif :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = read_dataset(ftesta_bert, row_limit=1000,projecter=random_projecter, label_of_interest=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tPredicted\n",
      "\t\t0\t1\n",
      "Actual\t0\t900\t24\n",
      "\t1\t4\t72\n",
      "\n",
      "Error rate\t\t0.028\n",
      "False alarm rate\t0.025974\n",
      "Detection rate\t\t0.947368\n",
      "F-score\t\t\t0.837209\n",
      "Precision\t\t0.75\n",
      "\n",
      "CPU times: user 3.49 s, sys: 4.86 ms, total: 3.49 s\n",
      "Wall time: 3.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "confusion_matrix = classifier.estimate_all(test_dataset)\n",
    "print(confusion_matrix.PrintEvaluation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unload memory\n",
    "train_dataset = test_dataset = confusion_matrix = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyse :**\n",
    "Faire des estimations sur le jeu de données projeté est bien plus rapide : on a gagné un facteur 5 en temps d'exécution. Le classifieur est plutôt performant en terme de qualité des prédictions, même en travaillant sur des données projetées dans un espace de dimension 128.\n",
    "\n",
    "En terme de performance, par contre, ce classifieur est très mauvais : il n'est pas utilisable sur des jeux de données de la taille de ceux considérés dans ce projet ! Prédire les 1000 labels en utilisant 10000 points de références du jeu de données d'entraînement prend environ 3s sur mon système ; prédire les labels des 150000 lignes du jeu de données test en utilisant les 200000 points de référence est inenvisageable.\n",
    "\n",
    "Le choix de $k$ est important pour obtenir de bonnes performances prédictives. Les méthodes de _cross-validation_ permettent d'explorer les valeurs possibles pour l'hyperparamètre $k$, et d'évaluer de manière fiable les performances de classifieurs pour les différentes valeurs de $k$. Etant donné les limitations pratiques du classifieur K-nn en terme de temps de calcul, et ce même pour des valeurs de faibles $k$, du nombre d'observations pour l'entraînement, du nombre d'estimations à réaliser, et de la dimension des observations, nous avons décidé de ne pas suivre cette voie, et de plutôt essayer des méthodes différentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Classifieur binaire par régression logistique\n",
    "\n",
    "\n",
    "Un deuxième classifieur envisageable est le classifieur binaire par régression logistique. Etant donné la faiblesse du classifieur k-nn sur notre jeu de données, cette proposition est pertinente : l'étape d'estimation est en effet très peu coûteuse pour la régression logistique ($O(d)$ où $d$ est la dimension de l'espace des observations). Au contraire, l'étape coûteuse va être l'entraînement du classifieur : sera-t-elle trop coûteuse pour notre jeu de données relativement large ? Pour répondre à cette, nous allons devoir considérer les différentes implémentations possibles de cette étape d'entraînement.\n",
    "\n",
    "#### Commentaires sur les choix effectués \n",
    "\n",
    "Le classifieur `LogisticReg` est défini dans le fichier `LogisticReg.hpp`. L'étape d'entraînement y est effectuée par minimisation de la fonction de coût régularisée $J(\\beta)$ par descente de gradient. Les formules, et une partie des notations utilisées dans notre implémentation sont calqués sur celles utilisées sur [cette page](http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&doc=exercises/ex5/ex5.html) du cours *Machine Learning* d'Andrew Ng.\n",
    "\n",
    "Les choix d'implémentations de la descente de gradient se sont révélés être d'une importance fondamentale, et ont nécessité du travail pour assurer :\n",
    "\n",
    "- que la méthode converge rapidement : itérer avec des pas de taille trop petite n'est pas efficace.\n",
    "- que la méthode est stable : itérer avec des pas de taille  trop grande ne permet pas à la méthode de converger, voire la pousse à diverger.\n",
    "\n",
    "Nous avons implémenté différentes méthodes de descente de gradient, qui correspondent toute à un compromis :\n",
    "\n",
    "1. `fit_gd` : descente de gradient simple avec un pas de taille fixée $\\alpha$.\n",
    "    + $\\oplus$ simple à implémenter.\n",
    "    + $\\ominus$ pas généralement trop petit au début (convergence lente), et trop grand à la fin (instable).\n",
    "    + $\\ominus$ itération sur toutes les observations à chaque pas : coût $O(Nd)$\n",
    "2. `fit_newton` : méthode de Newton-Rhapson. La hessienne est inversée à l'aide de la librairie Eigen.\n",
    "    + $\\oplus$ assure une convergence quadratique sous des conditions faibles.\n",
    "    + $\\ominus$ inverser la hessienne est très coûteux ($\\approx O(N^3)$).\n",
    "3. `fit_sgd` : *stochastic gradient descent*, à chaque pas on estime le gradient sur un nombre réduit d'observations prises au hasard.\n",
    "    + $\\oplus$ coût du pas ne dépend plus du nombre d'observations, mais seulement de la dimension des observations ($O(d)$).\n",
    "    + $\\oplus$ *minibatching* : on a pris soin de vectoriser les opérations sur les _batchs_ de 512 instances prises au hasard, en utilisant des opérations Eigen.\n",
    "    - $\\oplus$ relativement simple à implémenter.\n",
    "    - $\\ominus$ même problème de choix de la taille du pas que la descente de gradient simple.\n",
    "    \n",
    "De ces trois solutions, la méthode stochastique est la plus prometteuse : les deux autres ne sont plus applicables lorsque le nombre d'observation $N$ devient grand (en pratique dès $N > 10000$). Le choix de la taille du pas reste problématique : il serait intéressant d'avoir un grand pas pour les premières itérations, et un plus petit pas à mesure qu'on s'approche de l'optimum. Nous avons donc décidé d'implémenter une méthode de descente de gradient stochastique à pas adaptatif.\n",
    "\n",
    "De nombreuses méthodes, appelées \"accélérateurs de convergence\", peuvent être associés à la descente de gradient pour en faire varier le pas à chaque itération. Les [notes de cours de Marc Lelarge](https://mlelarge.github.io/dataflowr-slides/X/lesson4.html), nous ont permis d'avoir un aperçu de ces méthodes. Nous avons choisi d'implémenter la méthode RMSProp, qui constitue un bon compromis entre difficulté d'implémentation (en particulier avec des opérations vectorisées) et performance. [La page dédiée](http://www.d2l.ai/chapter_optimization/rmsprop.html) du cours _Dive into deep learning_ nous a servi de référence. On obtient en fin de compte la méthode \n",
    "\n",
    "4. `fit_sgd_rmsprop` :\n",
    "    - $\\oplus$ stochastique, et donc dont le coût d'un pas ne dépend pas du nombre $N$ d'observations.\n",
    "    - $\\oplus$ avec _minibatching_, donc utilisant des opérations vectorisées.\n",
    "    - $\\oplus$ avec pas adaptatif, et ce par coefficient du gradient, donnant une convergence rapide et stable.\n",
    "    - $\\ominus$ avec une implémentation relativement complexe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Démonstration et comparaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constante de régularistation\n",
    "LAMBDA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge ici toutes les lignes en mémoire.\n",
    "train_dataset = read_dataset(ftrain_bert, label_of_interest=4)\n",
    "test_dataset = read_dataset(ftesta_bert, label_of_interest=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Descente de gradient simple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J(beta) = 55.37\n",
      "\n",
      "CPU times: user 4.17 s, sys: 16.6 ms, total: 4.19 s\n",
      "Wall time: 4.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = info9.LogisticReg(train_dataset, LAMBDA, decision_threshold=0.5)\n",
    "classifier.fit_gd(epsilon=0.75, alpha=0.01)\n",
    "print(f\"J(beta) = {classifier.J():.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tPredicted\n",
      "\t\t0\t1\n",
      "Actual\t0\t143974\t585\n",
      "\t1\t6090\t3318\n",
      "\n",
      "Error rate\t\t0.0433534\n",
      "False alarm rate\t0.00404679\n",
      "Detection rate\t\t0.352679\n",
      "F-score\t\t\t0.498535\n",
      "Precision\t\t0.850115\n",
      "\n",
      "CPU times: user 174 ms, sys: 104 µs, total: 174 ms\n",
      "Wall time: 173 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cm = classifier.estimate_all(test_dataset)\n",
    "print(cm.PrintEvaluation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Descente de gradient simple par méthode de Newton-Rhapson**\n",
    "\n",
    "Il faut prendre un plus petit jeu de données pour pouvoir tester cette méthode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_train_dataset = read_dataset(ftrain_bert, row_limit=400,label_of_interest=4)\n",
    "classifier = info9.LogisticReg(smaller_train_dataset, LAMBDA, decision_threshold=0.5)\n",
    "smaller_train_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_small(beta) = 0.02\n",
      "\n",
      "CPU times: user 3.05 s, sys: 10.2 ms, total: 3.06 s\n",
      "Wall time: 2.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier.fit_newton(epsilon=1)\n",
    "print(f\"J_small(beta) = {classifier.J():.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.Descente de gradient stochastique avec mini-batching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J(beta) = 8.49\n",
      "\n",
      "CPU times: user 3.08 s, sys: 3.48 ms, total: 3.08 s\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = info9.LogisticReg(train_dataset, LAMBDA, decision_threshold=0.5)\n",
    "classifier.fit_sgd(epsilon=1, alpha=0.1)\n",
    "print(f\"J(beta) = {classifier.J():.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Descente de gradient stochastique avec mini-batching + accélérateur de convergence RMSProp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J(beta) = 7.03\n",
      "\n",
      "CPU times: user 3.99 s, sys: 10.9 ms, total: 4 s\n",
      "Wall time: 3.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = info9.LogisticReg(train_dataset, LAMBDA, decision_threshold=0.5)\n",
    "classifier.fit_sgd_rmsprop(epsilon=0.1)\n",
    "print(f\"J(beta) = {classifier.J():.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tPredicted\n",
      "\t\t0\t1\n",
      "Actual\t0\t144250\t309\n",
      "\t1\t1956\t7452\n",
      "\n",
      "Error rate\t\t0.0147109\n",
      "False alarm rate\t0.00213754\n",
      "Detection rate\t\t0.792092\n",
      "F-score\t\t\t0.868076\n",
      "Precision\t\t0.960186\n",
      "\n",
      "CPU times: user 180 ms, sys: 0 ns, total: 180 ms\n",
      "Wall time: 179 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cm = classifier.estimate_all(test_dataset)\n",
    "print(cm.PrintEvaluation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = test_dataset = cm = classifier = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparaison :**\n",
    "\n",
    "Un réal atout de la régression logistique est mis en avant ici : sa très bonne performance pour la prédiction, une fois qu'il a été entraîné ($\\approx$ 200ms sur mon PC pour estimer les labels des 150000 vecteurs du jeu de données `testa`).\n",
    "\n",
    "En ce qui concerne la phase d'entraînement, on a ici choisi des paramètres pour obtenir une durée d'entraînement de l'ordre de 3s ; ce choix a été fait pour garder l'interactivité du notebook, mais ne serait pas justifié pour une situation d'entraînement réel. On peut en effet comparer la performance des différentes méthodes en comparant la valeur de la fonction de coût régularisée $J(\\beta)$ après l'entraînement : les méthodes étant entraînées sur les mêmes données (sauf pour la méthode de Newton, trop lente), la fonction de coût est la même, et une plus petite valeur de $J(\\beta)$ indique donc une plus grande proximité avec le $\\beta_\\text{opt}$ qui minimise le coût. Pour 3s de temps de calcul, on obtient le tableau suivant :\n",
    "\n",
    "|Méthode| J($\\beta$) |\n",
    "|-------|-----------|\n",
    "| Fixed-step GD | 55.4 |\n",
    "| Newton | *échec* |\n",
    "|Stochastic GD |8.5|\n",
    "|Stochastic GD + RMSProp | 7.1|\n",
    "\n",
    "On obtient bien les gains de performances espérés avec les méthodes stochastiques. Par ailleurs, d'un point de vue expérimental, nous avons observé une bien plus grande stabilité de la méthode stochastique avec RMSProp par rapport à la méthode stochastique en les essayant avec différents paramètres sur les jeux de données.\n",
    "\n",
    "Enfin, les performances en terme de prédiction du classifieur ainsi obtenu sont excellentes : presque 80% de taux de détéction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Problème de la classification multilabel\n",
    "\n",
    "En passant par la classification binaire, on \"jette\" une partie de l'information dont on dispose sur le jeu de données d'entraînement. Serait-il possible d'obtenir de meilleure performance en revenant au problème plus général de la reconnaissance d'entités nommés ? Nous allons maintenant commenter nos implémentations de classifieurs multiclasses (problème 5.3 de l'énoncé).\n",
    "\n",
    "### 5.1. Classifieur K-nn multilabel\n",
    "\n",
    "Le classifieur K-nn multilabel classique suit le même principe que le classifieur K-nn binaire : il détermine la classe d'un point en effectuant un vote majoritaire sur les K plus proches voisins de ce point. On retrouve ici le problème posé par le désequilibre des effectifs des classes : la classe \"O\" étant très largement plus grande que les autres, elle risque de gagner tous les votes majoritaires. Traiter la classe \"O\" séparément n'est pas raisonnable : la classe \"I-PER\" est elle-même plus de deux fois plus large que la classe \"I-MISC\" dans le jeu de données `testa`.\n",
    "\n",
    "Une solution qui traite toute les classes de la même manière consiste à donner moins de poids aux classes les plus grandes en divisant la valeur d'un vote par l'effectif total de la classe, i.e. à normaliser à 1 la valeur totale des votes de chaque classe :\n",
    "\n",
    "\\begin{equation*}\n",
    "p(c \\in k) = \\sum_{n \\in K_{nn}(c)} \\frac{\\mathbf{1}\\left\\{n \\in k\\right\\}}{\\left|k\\right|}\n",
    "\\end{equation*}\n",
    "\n",
    "La valeur des votes cumulés des membres de la classe $k$ pour le point $c$ est égal au nombre de votants de la classe $k$ parmi les voisins de $c$ divisé par l'effectif total de la classe $k$.\n",
    "\n",
    "C'est cette solution que nous avons utilisée dans notre implémentation de la classe `KnnClassificationMulticlass`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Démonstration :**\n",
    "\n",
    "Nous avons vu que le classifieur K-nn est peu performant lorsque les observations sont dans un espace de grande dimension ; on va donc présenter l'utilisation du classifieur K-nn multilabel directement sur un jeu de donnée projeté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "random_projecter = info9.RandomProjection(1024, 128, \"Rademacher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fois-ci, le jeu de données contient des labels prenant des valeurs dans {0, ..., 8}\n",
    "train_dataset = read_dataset(ftrain_bert, row_limit=10000, projecter=random_projecter)\n",
    "test_dataset = read_dataset(ftesta_bert, row_limit=1000, projecter=random_projecter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = info9.KnnClassificationMulticlass(k, train_dataset, IOB_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tO\tB-MISC\tI-MISC\tB-PER\tI-PER\tB-ORG\tI-ORG\tB-LOC\tI-LOC\t\n",
      "O\t446\t7\t75\t0\t72\t0\t83\t0\t103\t\n",
      "B-MISC\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "I-MISC\t0\t0\t7\t0\t1\t0\t0\t0\t3\t\n",
      "B-PER\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "I-PER\t0\t0\t1\t0\t70\t0\t3\t0\t2\t\n",
      "B-ORG\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "I-ORG\t1\t5\t4\t0\t3\t0\t61\t0\t3\t\n",
      "B-LOC\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "I-LOC\t3\t0\t2\t0\t3\t0\t15\t0\t27\t\n",
      "\n",
      "CPU times: user 2.77 s, sys: 6.86 ms, total: 2.78 s\n",
      "Wall time: 2.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cm = classifier.estimate_all(test_dataset)\n",
    "print(cm.PrintMatrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs all for class \"I-PER\"\n",
      "\t\tPredicted\n",
      "\t\t0\t1\n",
      "Actual\t0\t845\t79\n",
      "\t1\t6\t70\n",
      "\n",
      "Error rate\t\t0.085\n",
      "False alarm rate\t0.0854978\n",
      "Detection rate\t\t0.921053\n",
      "F-score\t\t\t0.622222\n",
      "Precision\t\t0.469799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"One vs all for class \\\"I-PER\\\"\")\n",
    "print(cm.OneVsAllConfusionMatrix(4).PrintEvaluation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unload data\n",
    "train_dataset = test_dataset = classifier = cm = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyse :** Le classifieur K-nn multilabel présente les même caractéristiques que le classifieur K-nn binaire :\n",
    "\n",
    "- il est très lent pour la prédiction, et nécessite que les données soit projetées dans un espace de petite dimension pour avoir un temps d'exécution raisonnable.\n",
    "- la qualité de ses prédictions est bonne, mais pas excellente.\n",
    "\n",
    "Sur un même jeu de données (les 10000 premières lignes des données d'entraînements, et les 1000 premières lignes des données de test), le classifieur multilabel est marginalement plus lent sur mon système (de 4%). Comparons la qualité de leurs prédictions pour la classe \"I-PER\" seule :\n",
    "\n",
    "|        | Binaire | Multilabel |\n",
    "|--------|---------|------------|\n",
    "| Error rate | 3% | 7% |\n",
    "| False alarm rate | 2% | 6% |\n",
    "| Detection rate | 93% | 81%|\n",
    "| F-Score | 84% | 63%|\n",
    "| Precision | 75% | 50% |\n",
    "\n",
    "Il semble donc que le classifieur K-nn binaire est plus performant pour discriminer la classe \"I-PER\" des autres classes que le classifieur multilabel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Régression logistique multinomiale\n",
    "\n",
    "La formulation de la régression logistique pour deux classes se généralise pour plusieurs classes en faisant apparaître la fonction *softmax* :\n",
    "\n",
    "\\begin{equation*}\n",
    "softmax(\\mathbf{z}) = \\frac{\\left[\\exp(z_1) \\, , \\, ... \\, , \\, \\exp(z_k)\\right]}{\\sum_{i=1}^k \\exp(z_i)}\n",
    "\\end{equation*}\n",
    "\n",
    "Les notations utilisées dans notre code, ainsi que la dérivations de la fonction de perte, et de son gradient, proviennent de [ce cours de l'Université de Buffalo](https://cedar.buffalo.edu/~srihari/CSE574/Chap4/4.3.4-MultiLogistic.pdf). Nous avons ajouté à cette fonction de perte un terme de régularisation.\n",
    "\n",
    "Ayant constaté le succès de la méthode stochastique avec RMSProp (`fit_sgd_rmsprop`) pour la régression logistique binaire, nous avons décidé d'implémenter cette méthode pour la version multinomiale. Afin d'éviter l'introduction de trop de complexité d'un seul coup, nous avons commencé par en implémenter une version à pas fixe (`fit_sgd`).\n",
    "\n",
    "Ici encore, nous mettons en oeuvre du minibatching pour améliorer les performances.\n",
    "\n",
    "**Démonstration :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constante de régularisation\n",
    "LAMBDA = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge ici toutes les lignes en mémoire. Ici, les labels prennent leur valeur dans {0, ..., 7}\n",
    "train_dataset = read_dataset(ftrain_bert)\n",
    "test_dataset = read_dataset(ftesta_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J(W) = 24.14\n",
      "\n",
      "CPU times: user 16.2 s, sys: 53.1 ms, total: 16.3 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = info9.LogisticRegMultinomial(train_dataset, LAMBDA, IOB_LABELS)\n",
    "classifier.fit_sgd(epsilon=1,alpha=0.1)\n",
    "print(f\"J(W) = {classifier.J():.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J(W) = 21.94\n",
      "\n",
      "CPU times: user 12.4 s, sys: 42.9 ms, total: 12.4 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = info9.LogisticRegMultinomial(train_dataset, LAMBDA, IOB_LABELS)\n",
    "classifier.fit_sgd_rmsprop(epsilon=1)\n",
    "print(f\"J(W) = {classifier.J():.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tO\tB-MISC\tI-MISC\tB-PER\tI-PER\tB-ORG\tI-ORG\tB-LOC\tI-LOC\t\n",
      "O\t127711\t0\t66\t0\t204\t0\t150\t0\t66\t\n",
      "B-MISC\t0\t0\t12\t0\t0\t0\t0\t0\t0\t\n",
      "I-MISC\t714\t0\t2394\t0\t54\t0\t228\t0\t402\t\n",
      "B-PER\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "I-PER\t1209\t0\t18\t0\t8076\t0\t63\t0\t42\t\n",
      "B-ORG\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "I-ORG\t576\t0\t177\t0\t90\t0\t5103\t0\t330\t\n",
      "B-LOC\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "I-LOC\t303\t0\t129\t0\t69\t0\t246\t0\t5535\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = classifier.estimate_all(test_dataset)\n",
    "print(cm.PrintMatrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs all for class \"I-PER\"\n",
      "\t\tPredicted\n",
      "\t\t0\t1\n",
      "Actual\t0\t144142\t417\n",
      "\t1\t1332\t8076\n",
      "\n",
      "Error rate\t\t0.0113596\n",
      "False alarm rate\t0.00288464\n",
      "Detection rate\t\t0.858418\n",
      "F-score\t\t\t0.902296\n",
      "Precision\t\t0.950901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"One vs all for class \\\"I-PER\\\"\")\n",
    "print(cm.OneVsAllConfusionMatrix(4).PrintEvaluation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyse :** Comme pour la version binaire, les méthodes stochastiques nous permettent d'entraîner notre classifieur sur l'ensemble des observations du jeu de données d'entraînement. L'ajout d'un optimiseur de convergence, dont l'implémentation est plus complexe que pour la version binaire, est très bénéfique : il permet à la fois d'accélerer et de stabiliser la convergence.\n",
    "\n",
    "On obtient en fin de compte un classifieur multiclasse très performant (>90% detection rate pour chaque classe) après une période d'entraînement très courte (seulement quelques secondes !). En observant les résultats de *one-vs-all* pour \"I-PER\", on constate que pour la régression logistique, on arrive aussi bien à distinguer \"I-PER\" des autres dans le contexte multilabel que dans le contexte binaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "Dans ce projet, nous avons étudié l'utilisation de techniques de science des données pour identifier les noms de personnes dans un texte, et plus généralement d'y reconnaître des entités. Notre rapport se termine par une belle réussite : la régression logistique multinomiale s'est révélée être très performante, à la fois sur le plan du temps de calcul, que sur celui de la qualité des prédictions.\n",
    "\n",
    "La question qui reste ouverte dans ce rapport est celle de la transformation du texte à anonymiser en un ensemble de vecteurs. Les techniques simples que nous avions mises en place n'ayant pas donné de résultats probants, nous avons choisi de nous concentrer ici sur notre travail pour la deuxième étape, celle de l'entraînement d'un classifieur. Ce travail a d'abord été un travail de sciences des données au sens de sciences des méthodes statistiques, mais il nous a également donné l'occasion d'en explorer d'autres facettes : calcul haute performance, méthode d'optimisation, interfaçage entre les langages C++ et Python, par exemple. Il nous aura également donné l'occasion de nous plonger dans les cours, exemples, et projets partagés au sein de la communauté des *data scientists*. Dans ce contexte, une méthode d'analyse de données est toujours imparfaite : parmi les multiples variantes, extensions, choix d'implémentation, elle constitue un compromis. Ce rapport aura été pour nous l'occasion de voir les limites et les atouts de certaines de ces méthodes, et d'aboutir à un compromis qui réponde à nos attentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Références\n",
    "\n",
    "\\[1\\] : Le cours [*Machine Learning*](http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=MachineLearning) d'Andrew Ng, notamment la page [\"Exercice 5 - Regularization\"](http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&doc=exercises/ex5/ex5.html) pour la formulation de la régression logistique pour la méthode de Newton.\n",
    "\n",
    "\\[2\\] : La [documentation de scikit-learn](https://scikit-learn.org/stable/user_guide.html) pour sa page [\"Stochastic Gradient Descent\"](https://scikit-learn.org/stable/modules/sgd.html) qui donne une formulation mathématique et des conseils d'implémentation pour la SGD. Egalement intéressant sur le sujet de la régularisation.\n",
    "\n",
    "\\[3\\] : Le cours [*Dive into Deep Learning*](http://www.d2l.ai/index.html#) pour sa [discussion sur les minibatchs pour la SGD](https://d2l.ai/chapter_optimization/minibatch-sgd.html).\n",
    "\n",
    "\\[4\\] : Le cours [*Deep learning: DIY!*](https://mlelarge.github.io/dataflowr-web/dldiy_ens.html) de Marc Lelarge notamment le chapitre [\"Optimization for deep learning\"](https://mlelarge.github.io/dataflowr-slides/X/lesson4.html#1) pour les accélérateurs de convergence.\n",
    "\n",
    "\\[5\\] : Le cours [*Multiclass Logistic Regression*](https://cedar.buffalo.edu/~srihari/CSE574/Chap4/4.3.4-MultiLogistic.pdf) de Sargur N. Srihari, pour la formulation de la régression logistique multinomiale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
